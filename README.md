# U-net
created a U-net for semantic segmentation task 

![U-Net Architecture](https://b2633864.smushcdn.com/2633864/wp-content/uploads/2022/02/1_unet_architecture_paper-1024x569.png?lossy=2&strip=1&webp=1)


## U-Net Architecture

U-Net is a convolutional neural network architecture designed for semantic segmentation tasks. It consists of an encoder-decoder structure with skip connections. The encoder is responsible for downsampling the input image to capture high-level features, while the decoder upsamples the features to generate the segmentation mask.

### Encoder (Downsampling)

In the encoder, the input image is passed through a series of convolutional layers followed by max pooling layers. This process gradually reduces the spatial dimensions of the image while increasing the number of features. For example, we may go from an input size of 128x128x3 to a feature map size of 8x8x128.

### Decoder (Upsampling)

The decoder takes the features generated by the encoder and upsamples them to the original image size. This process restores the spatial information lost during downsampling. It typically involves transposed convolutional layers (also known as "deconvolution" or "upconvolution").

### Skip Connections

To preserve fine-grained details and mitigate information loss during downsampling, U-Net uses skip connections. These connections directly link corresponding layers in the encoder and decoder. By concatenating the feature maps from the encoder with those from the decoder, the network can recover spatial information lost during downsampling.

For example, in TensorFlow, skip connections are implemented using the `tf.keras.layers.concatenate` function. This syntax allows the feature maps from the encoder and decoder to be concatenated along the channel dimension.


# U-Net Model Implementation with TensorFlow on Pet Dataset

This repository contains a Jupyter Notebook (`ipynb`) that demonstrates the implementation of a U-Net model using TensorFlow. The model is trained on the Pet Dataset from TensorFlow Datasets (TFDS), which consists of images of cats and dogs. The notebook preprocesses the images by resizing them to 128x128 pixels to match the input size expected by the U-Net model.

## Usage

To use this notebook:

1. Download the `ipynb` file.
2. Open the notebook in a Jupyter environment.
3. Run all cells sequentially.

This will execute the code for loading the dataset, preprocessing the images, defining the U-Net model architecture, training the model, and evaluating its performance. Feel free to customize the notebook for your specific datasets or experiment with different model configurations.

## Requirements

- TensorFlow
- TensorFlow Datasets (TFDS)
- Jupyter Notebook

